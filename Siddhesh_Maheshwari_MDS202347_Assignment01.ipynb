{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUcEZXcSpsLj4Q8M8ZZkwX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 1\n",
        "\n",
        "Submission date: End of day September 1, 2024\n",
        "Use this partial data set (sourced from Kaggle) which contains research\n",
        "articles related to COVID-19. This corpus has around 56000+ files. In this\n",
        "assignment, you will perform a set of tasks as given below.\n",
        "Tasks\n",
        "1. Extract the text content from the JSON-encoded data set and create a\n",
        "text corpus. You may use any JSON library to extract the text (2 marks).\n",
        "2. Develop your pre-processing steps (case-folding, removal of numbers, etc.)\n",
        "and order of steps (5 marks)\n",
        "3. Find the weighted term frequency for every word in the corpus and order\n",
        "it according to its rank using Zipf’s Law. Find the value of the α using\n",
        "the data obtained from the previous step (8 marks).\n",
        "4. Print the number of tokens and the vocabulary (5 marks)\n",
        "5. Plot Tokens Vs Vocabulary graph using Heaps’ empirical law. Find Vocabulary count for every 10000 tokens. You may use a log scale for plotting\n",
        "(5 marks)\n"
      ],
      "metadata": {
        "id": "Jv9oHjUCODwS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt2xcN9ENp4o"
      },
      "outputs": [],
      "source": []
    }
  ]
}